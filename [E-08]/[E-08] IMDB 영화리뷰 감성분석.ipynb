{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9641fe4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be67ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33e793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7813a2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84c9e745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63fbea96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bc12f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "031d117a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4225562b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/2733197300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m     if any(isinstance(x, (\n\u001b[1;32m    984\u001b[0m         tf.Tensor, np.ndarray, float, int)) for x in input_list):\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3297\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "335723d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4509f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71877feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.03629824 -0.00365709  0.03653086 -0.03406229]\n",
      "  [ 0.03861101  0.02322917 -0.01219317  0.00448895]\n",
      "  [ 0.03434856 -0.03116089  0.04772184 -0.01275691]\n",
      "  [-0.04855501 -0.01155505 -0.02671237 -0.01640601]\n",
      "  [ 0.01239675  0.00216961  0.00155388  0.01825187]]\n",
      "\n",
      " [[ 0.03629824 -0.00365709  0.03653086 -0.03406229]\n",
      "  [ 0.03861101  0.02322917 -0.01219317  0.00448895]\n",
      "  [ 0.00612124  0.03686637  0.02688079 -0.00759522]\n",
      "  [-0.01590054  0.04994554  0.04813856  0.04205832]\n",
      "  [ 0.01239675  0.00216961  0.00155388  0.01825187]]\n",
      "\n",
      " [[ 0.03629824 -0.00365709  0.03653086 -0.03406229]\n",
      "  [-0.02394288  0.04231504  0.0230738   0.04963762]\n",
      "  [ 0.03861101  0.02322917 -0.01219317  0.00448895]\n",
      "  [ 0.03434856 -0.03116089  0.04772184 -0.01275691]\n",
      "  [ 0.03543513  0.02111636 -0.02961244 -0.01454449]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# tf.keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype=object)\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75993f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2efb9e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d9d26a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80217bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22368f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c05ff1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "843afdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "# 보정 전 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ad7032c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n",
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다.\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다.\n",
    "\n",
    "# 보정 후 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67460c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fdf9037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c803e118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c232b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,145\n",
      "Trainable params: 160,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "# [[YOUR CODE]]\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8a06656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb260d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 6s 17ms/step - loss: 0.6908 - accuracy: 0.5187 - val_loss: 0.6868 - val_accuracy: 0.5756\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.6787 - accuracy: 0.7248 - val_loss: 0.6701 - val_accuracy: 0.7471\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6563 - accuracy: 0.7883 - val_loss: 0.6446 - val_accuracy: 0.7948\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6220 - accuracy: 0.8168 - val_loss: 0.6067 - val_accuracy: 0.8088\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5714 - accuracy: 0.8407 - val_loss: 0.5542 - val_accuracy: 0.8238\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.5094 - accuracy: 0.8503 - val_loss: 0.4985 - val_accuracy: 0.8311\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4489 - accuracy: 0.8597 - val_loss: 0.4509 - val_accuracy: 0.8344\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3977 - accuracy: 0.8678 - val_loss: 0.4154 - val_accuracy: 0.8382\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3565 - accuracy: 0.8765 - val_loss: 0.3902 - val_accuracy: 0.8398\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.3236 - accuracy: 0.8855 - val_loss: 0.3724 - val_accuracy: 0.8440\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2959 - accuracy: 0.8935 - val_loss: 0.3600 - val_accuracy: 0.8459\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2722 - accuracy: 0.9028 - val_loss: 0.3518 - val_accuracy: 0.8469\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2515 - accuracy: 0.9095 - val_loss: 0.3463 - val_accuracy: 0.8485\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2332 - accuracy: 0.9171 - val_loss: 0.3428 - val_accuracy: 0.8496\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2165 - accuracy: 0.9231 - val_loss: 0.3408 - val_accuracy: 0.8525\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.2014 - accuracy: 0.9298 - val_loss: 0.3405 - val_accuracy: 0.8516\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1873 - accuracy: 0.9361 - val_loss: 0.3411 - val_accuracy: 0.8536\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1743 - accuracy: 0.9410 - val_loss: 0.3426 - val_accuracy: 0.8544\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1623 - accuracy: 0.9463 - val_loss: 0.3450 - val_accuracy: 0.8538\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.1512 - accuracy: 0.9517 - val_loss: 0.3480 - val_accuracy: 0.8528\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da4a1004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - loss: 0.3698 - accuracy: 0.8401\n",
      "[0.36979758739471436, 0.8400800228118896]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6ee5168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "720b7ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b656218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsmklEQVR4nO3de5xVdb3/8ddnuDgMV7koCgjaQfGCXMUwL5hWeAnDJEEySY+mph79nTT9Wcqx+JVl6bG8oXnJUCxPERZmapqerJwRkYS8oIJCqAgIw2W4fn5/fNeGPZu9ZzYzs/bes9f7+Xjsx173/dlr9nw/a32/a32XuTsiIpJcFcUOQEREikuJQEQk4ZQIREQSTolARCThlAhERBJOiUBEJOGUCGQXZva4mZ3T0ssWk5ktNrMTY9ium9m/RcN3mtm381m2CZ8z2cz+2NQ4RRpiuo+gPJjZurTRKmATsC0a/5q7zyh8VKXDzBYD/+7uT7Xwdh0Y6O6LWmpZMxsAvAO0c/etLRKoSAPaFjsAaRnu3ik13FChZ2ZtVbhIqdDvsTSoaqjMmdkYM1tqZt80s/eB+8xsTzP7nZmtMLPV0XDftHWeNbN/j4anmNn/mtlN0bLvmNlJTVx2fzN7zsxqzewpM7vNzH6RI+58YvyOmf0l2t4fzaxn2vyzzWyJma00s2sb2D9Hmtn7ZtYmbdp4M5sfDY8ys7+a2cdmttzMfmpm7XNs634z+27a+JXROv8ys3Mzlj3FzF42s7Vm9p6ZTU2b/Vz0/rGZrTOz0al9m7b+UWZWbWZrovej8t03u7mfu5vZfdF3WG1ms9LmnWZm86Lv8JaZjY2m16uGM7Opqb+zmQ2IqsjOM7N3gT9F038V/R3WRL+RQ9PW72BmP4r+nmui31gHM/u9mV2a8X3mm9n4bN9VclMiSIbeQHegP3AB4e9+XzS+H7AR+GkD6x8JvA70BH4A/MzMrAnLPgS8CPQApgJnN/CZ+cR4FvBVYC+gPfANADM7BLgj2v6+0ef1JQt3/zuwHvh0xnYfioa3AVdE32c0cAJwcQNxE8UwNornM8BAILN9Yj3wFaAbcApwkZl9IZp3bPTezd07uftfM7bdHfg9cGv03X4M/N7MemR8h132TRaN7ecHCVWNh0bbujmKYRTwc+DK6DscCyzO8RnZHAccDHwuGn+csJ/2AuYC6VWZNwEjgKMIv+OrgO3AA8CXUwuZ2RCgD2HfyO5wd73K7EX4hzwxGh4DbAYqG1h+KLA6bfxZQtUSwBRgUdq8KsCB3ruzLKGQ2QpUpc3/BfCLPL9Tthi/lTZ+MfCHaPg6YGbavI7RPjgxx7a/C9wbDXcmFNL9cyx7OfCbtHEH/i0avh/4bjR8L/D9tOUOTF82y3ZvAW6OhgdEy7ZNmz8F+N9o+GzgxYz1/wpMaWzf7M5+BvYhFLh7ZlnurlS8Df3+ovGpqb9z2nc7oIEYukXLdCUkqo3AkCzLVQKrCe0uEBLG7XH8T5X7S2cEybDC3etSI2ZWZWZ3RafaawlVEd3Sq0cyvJ8acPcN0WCn3Vx2X2BV2jSA93IFnGeM76cNb0iLad/0bbv7emBlrs8iHP2fbmZ7AKcDc919SRTHgVF1yftRHP+PcHbQmHoxAEsyvt+RZvZMVCWzBrgwz+2mtr0kY9oSwtFwSq59U08j+7kf4W+2Osuq/YC38ow3mx37xszamNn3o+qltew8s+gZvSqzfVb0m34E+LKZVQCTCGcwspuUCJIh89Kw/wQOAo509y7srIrIVd3TEpYD3c2sKm1avwaWb06My9O3HX1mj1wLu/tCQkF6EvWrhSBUMb1GOOrsAvzfpsRAOCNK9xAwG+jn7l2BO9O229ilfP8iVOWk2w9YlkdcmRraz+8R/mbdsqz3HvCJHNtcTzgbTOmdZZn073gWcBqh+qwr4awhFcNHQF0Dn/UAMJlQZbfBM6rRJD9KBMnUmXC6/XFU33x93B8YHWHXAFPNrL2ZjQY+H1OMjwKnmtnRUcPuDTT+W38I+A9CQfirjDjWAuvMbBBwUZ4x/BKYYmaHRIkoM/7OhKPtuqi+/ay0eSsIVTIH5Nj2HOBAMzvLzNqa2ZnAIcDv8owtM46s+9ndlxPq7m+PGpXbmVkqUfwM+KqZnWBmFWbWJ9o/APOAidHyI4Ez8ohhE+GsrYpw1pWKYTuhmu3HZrZvdPYwOjp7Iyr4twM/QmcDTaZEkEy3AB0IR1t/A/5QoM+dTGhwXUmol3+EUABkcwtNjNHdFwBfJxTuywn1yEsbWe1hQgPmn9z9o7Tp3yAU0rXA3VHM+cTwePQd/gQsit7TXQzcYGa1hDaNX6atuwGYBvzFwtVKn8zY9krgVMLR/EpC4+mpGXHn6xYa3s9nA1sIZ0UfEtpIcPcXCY3RNwNrgD+z8yzl24Qj+NXAf1H/DCubnxPOyJYBC6M40n0D+AdQDawCbqR+2fVzYDChzUmaQDeUSdGY2SPAa+4e+xmJlC8z+wpwgbsfXexYWiudEUjBmNkRZvaJqCphLKFeeFaRw5JWLKp2uxiYXuxYWjMlAimk3oRLG9cRroG/yN1fLmpE0mqZ2ecI7Skf0Hj1kzRAVUMiIgmnMwIRkYRrdZ3O9ezZ0wcMGFDsMEREWpWXXnrpI3fvlW1eq0sEAwYMoKampthhiIi0KmaWeTf6DqoaEhFJOCUCEZGEUyIQEUm4VtdGkM2WLVtYunQpdXV1jS8sRVFZWUnfvn1p165dsUMRkQxlkQiWLl1K586dGTBgALmflyLF4u6sXLmSpUuXsv/++xc7HBHJUBZVQ3V1dfTo0UNJoESZGT169NAZm0gTzZgBAwZARUV4nzGjsTV2T1mcEQBKAiVOfx+RppkxAy64ADZEj3RasiSMA0ye3DKfURZnBCIi5eraa3cmgZQNG8L0lqJE0AJWrlzJ0KFDGTp0KL1796ZPnz47xjdv3tzgujU1NVx22WWNfsZRRx3VUuGKSIE1p2rn3Xd3b3pTJDIRtHR9W48ePZg3bx7z5s3jwgsv5Iorrtgx3r59e7Zu3Zpz3ZEjR3Lrrbc2+hkvvPBC84IUkaJIVe0sWQLuO6t28i139st8yGkj05sicYmguX+UfE2ZMoULL7yQI488kquuuooXX3yR0aNHM2zYMI466ihef/11AJ599llOPfVUAKZOncq5557LmDFjOOCAA+oliE6dOu1YfsyYMZxxxhkMGjSIyZMnk+pBds6cOQwaNIgRI0Zw2WWX7dhuusWLF3PMMccwfPhwhg8fXi/B3HjjjQwePJghQ4Zw9dVXA7Bo0SJOPPFEhgwZwvDhw3nrreY8r1ykdWrOwWNzq3amTYOqqvrTqqrC9Bbj7q3qNWLECM+0cOHCXabl0r+/e0gB9V/9++e9iQZdf/31/sMf/tDPOeccP+WUU3zr1q3u7r5mzRrfsmWLu7s/+eSTfvrpp7u7+zPPPOOnnHLKjnVHjx7tdXV1vmLFCu/evbtv3rzZ3d07duy4Y/kuXbr4e++959u2bfNPfvKT/vzzz/vGjRu9b9++/vbbb7u7+8SJE3dsN9369et948aN7u7+xhtveGp/zpkzx0ePHu3r1693d/eVK1e6u/uoUaP817/+tbu7b9y4ccf8ptidv5NIqfjFL9yrquqXF1VVYXo+zLKXOWa7F0P//mGd/v3z/+x0QI3nKFcTd0ZQiPq2lAkTJtCmTRsA1qxZw4QJEzjssMO44oorWLBgQdZ1TjnlFPbYYw969uzJXnvtxQcffLDLMqNGjaJv375UVFQwdOhQFi9ezGuvvcYBBxyw4zr9SZMmZd3+li1bOP/88xk8eDATJkxg4cKFADz11FN89atfpSo69OjevTu1tbUsW7aM8ePHA+GmsKrMQxORVqCYR/QtUbUzeTIsXgzbt4f3lrpaKCVxiaAQ9W0pHTt23DH87W9/m+OPP55XX32Vxx57LOc19XvssceO4TZt2mRtX8hnmVxuvvlm9t57b1555RVqamoabcwWae2aWx3c3IPHglTtNFPiEkGx/ihr1qyhT58+ANx///0tvv2DDjqIt99+m8WLFwPwyCOP5Ixjn332oaKiggcffJBt27YB8JnPfIb77ruPDdGhz6pVq+jcuTN9+/Zl1qxZAGzatGnHfJHWothH9JMnw/Tp0L8/mIX36dNb/qi+ORKXCIr1R7nqqqu45pprGDZs2G4dweerQ4cO3H777YwdO5YRI0bQuXNnunbtustyF198MQ888ABDhgzhtdde23HWMnbsWMaNG8fIkSMZOnQoN910EwAPPvggt956K4cffjhHHXUU77//fovHLtKYYl5+2RIHj3FX7TRbrsaDUn01t7G4nNXW1rq7+/bt2/2iiy7yH//4x0WOqD79naQpmttY2xIXiLREY22xocbiZLj77rsZOnQohx56KGvWrOFrX/tasUMSabZSuPyy5I/om0mJoIykbmRbuHAhM2bM0BU+UjKKWbXTGuroi61sOp0TkdLU3E7T9tsvrJNter4mT1bB3xCdEYhIrEqhakcapkQgIo1S1U55U9WQiDRIVTvlT2cELeD444/niSeeqDftlltu4aKLLsq5zpgxY6ipqQHg5JNP5uOPP95lmalTp+64nj+XWbNm7egmAuC6667jqaee2o3oRRqmqp3yp0TQAiZNmsTMmTPrTZs5c2bO/n4yzZkzh27dujXpszMTwQ033MCJJ57YpG2JZKOqnfKnRNACzjjjDH7/+9/v6Ldn8eLF/Otf/+KYY47hoosuYuTIkRx66KFcf/31WdcfMGAAH330EQDTpk3jwAMP5Oijj97RVTWEewSOOOIIhgwZwhe/+EU2bNjACy+8wOzZs7nyyisZOnQob731FlOmTOHRRx8F4Omnn2bYsGEMHjyYc889l02bNu34vOuvv57hw4czePBgXnvttV1iUnfV5aU5dfytodM0aZ6yayO4/HKYN69ltzl0KNxyS+753bt3Z9SoUTz++OOcdtppzJw5ky996UuYGdOmTaN79+5s27aNE044gfnz53P44Ydn3c5LL73EzJkzmTdvHlu3bmX48OGMGDECgNNPP53zzz8fgG9961v87Gc/49JLL2XcuHGceuqpnHHGGfW2VVdXx5QpU3j66ac58MAD+cpXvsIdd9zB5ZdfDkDPnj2ZO3cut99+OzfddBP33HNPvfX32msvnnzySSorK3nzzTeZNGkSNTU1PP744/z2t7/l73//O1VVVaxatQqAyZMnc/XVVzN+/Hjq6urYvn377u9oiUVz6/inTau/Pqhqp9zojKCFpFcPpVcL/fKXv2T48OEMGzaMBQsW1KvGyfT8888zfvx4qqqq6NKlC+PGjdsx79VXX+WYY45h8ODBzJgxI2c31imvv/46+++/PwceeCAA55xzDs8999yO+aeffjoAI0aM2NFRXTp1V10+mlvHr6qd8ld2ZwQNHbnH6bTTTuOKK65g7ty5bNiwgREjRvDOO+9w0003UV1dzZ577smUKVNydj/dmClTpjBr1iyGDBnC/fffz7PPPtuseFNdWefqxjq9u+rt27dTWVnZrM+T5pkxIxTc774bqmSmTcu/IG6JZ3Doqp3yFusZgZmNNbPXzWyRmV2dZX5/M3vazOab2bNm1jfOeOLUqVMnjj/+eM4999wdZwNr166lY8eOdO3alQ8++IDHH3+8wW0ce+yxzJo1i40bN1JbW8tjjz22Y15tbS377LMPW7ZsYUZaBW/nzp2pra3dZVsHHXQQixcvZtGiRUDoRfS4447L+/uou+rS0RqeeSutW2yJwMzaALcBJwGHAJPM7JCMxW4Cfu7uhwM3AN+LK55CmDRpEq+88sqORDBkyBCGDRvGoEGDOOuss/jUpz7V4PrDhw/nzDPPZMiQIZx00kkcccQRO+Z95zvf4cgjj+RTn/oUgwYN2jF94sSJ/PCHP2TYsGH1GmgrKyu57777mDBhAoMHD6aiooILL7ww7++i7qpLhy7flLiZRw8+b/ENm40Gprr756LxawDc/XtpyywAxrr7e2ZmwBp379LQdkeOHOmp6+9T/vnPf3LwwQe39FeQFqa/U9NUVIQzgUxm4SqcfDSnaknKg5m95O4js82Ls2qoD/Be2vjSaFq6V4DTo+HxQGcz65G5ITO7wMxqzKxmxYoVsQQrEpfmXLoJunxT4lfsq4a+ARxnZi8DxwHLgG2ZC7n7dHcf6e4je/XqVegYRZqsufX7oKodiV+ciWAZ0C9tvG80bQd3/5e7n+7uw4Bro2kfN+XD4qrikpaR1L9Pc+v3QZdvSvziTATVwEAz29/M2gMTgdnpC5hZTzNLxXANcG9TPqiyspKVK1cmtrApde7OypUrW+0lqMXseTNFVTsSp9juI3D3rWZ2CfAE0Aa4190XmNkNhGdnzgbGAN8zMweeA77elM/q27cvS5cuRe0HpauyspK+fVvf1cGl0POmSNxiu2ooLtmuGhKJy4AB2Qvy/v3DkXljMhMJhPp9Ve1IoRXrqiGRVk89b0oSlF0XEyItSQ9VkSTQGYGUveY09urSTUkCJQIpa829jl9VO5IEaiyWstbcxl6RcqHGYkmslrqOX6ScKRFIySv2YxZFyp0SgZS05tbxq7FXpHFKBFLS9JhFkfgpEUjsit1Xj/rpEWmYEoHESo9ZFCl9SgQSKz1mUaT0KRFIrNRXj0jpU19DEiv11SOt2bZtsGULbN4c3isqoF07aNs2vNq0CQcorZ0SgTSqOQ8+nzYtezfMqtpJBndYvx5WrIBVq0JBusce0L59eE8fbt8+FKz52rQJ1qwJr7Vr679nG167NqyzefPOgj01nGva9u2Nx5FKCukJIjWcOa19e6is3Pnd99ij4fHMeUceCQMHNv3vkfM7tPwmpZw098EsqWWamkiktLhDbW0o2FesgA8/3Dmc7fXhh1BXl//227TJnSTatQtJJVW4b97c+PY6dIAuXaBrV+jcORSs7dtDx47hPfVKFdINTWvbNiSGrVvDa8uWXYezTUsNp5JMXV3Yhx99FBJTXV14T73q6sKy2dxxRzyJQH0NSYPUV0/rsXkzrFsXXuvXZx+uq2v6a+PGUHjlKoCrqqBXL9hrr/Ce+erRIxSkmzfvPDJPFX6Z07Its2VLKMC7dg2vVAGfes+c1qVLKMBbo9R+ykwSPXvCnns2bZsN9TWkMwJpkPrqaTr3cCZVWxuqJWprdxaq6Ud/jQ2nxuvqQqGeq5DfunX34jMLR8yVlfVf6dO6das/r0eP3AV95tVd0nQVFTv3eSEoESRAc+r4k/7M3e3bYfnysO+WLq1f35wq4Bt65VPHnE2qIMisK+7UKRwV7703fOITYbhTp53TGxru2LF+Id+2bXk0dErzKRGUuebW8Zd7Y29dXSjklyzZ9X3JklD456qv7dRpZxVE6rX33rtO69Il1E+n6qgbagxMjbfVf6YUkNoIylxL1PE354yiULZubbjaZP16+PhjeO+9+oX9hx/W305FBey7b9g//fuH75sa7ts31M926RKSQIXuwpFWpKE2AiWCMldREeqqM5k1vdoibrW14Uh82bLwnhpevjzMy1bI53tlSocO9Qv31HDqvU+fcLWISLlRY3GClVIdv3u4ljy9cE8Np4+vXbvruj17wj77hKPxPfeEfv12r368U6dQNdO9u+rFRTIpEZS5QtTxb9oEH3wA77+f+7V8eXjPPHKvqIDevUO1y6BBcOKJ4ai8b9+dr333LdzVEyJJpERQ5lrihq5Vq6C6GubP31mgp79Wr86+Xo8e4Si+d284+uidBX56Qd+7txpGRYpNbQRSz/r1MHduKPhTr7fe2jm/qmpn4d7Qa6+9Wu/NPCLlSG0EktWWLfCPf4TC/sUXw/uCBTsbkfv1gyOOgPPPD+/DhjX9rkYRKV1KBAnhDm+8sbPAf/FFmDcv1O9DqMY54gj4whdg1KgwvPfexYxYRApFiaDMbdwIDz8MP/lJKPghXEkzYgRcckko8EeNCvcb6GoakWTSLTGtQFOe+fvuu3DNNaF657zzQjXQT38aqoLWrIE//xluugnOPBP2319JQCTJdEZQ4naniwh3eO65cPT/m9+EaePGwWWXwZgxKuxFJDtdNVTi8ukiYsMGeOihkADmzw8NuuefDxddFNYXEdFVQ61YQ91AL1kCt98O99wTrvU//HC4+2446yx1CSwi+VMiKHG5uoiorIQDDgjD48fDpZfCsceq+kdEdp8ai0vctGnZj+7btIGrroJ33oFHH4XjjlMSEJGmUSIocYceCqNH7yzk27UL9f8ffgjf+15yHhAjIvGJNRGY2Vgze93MFpnZ1Vnm72dmz5jZy2Y238xOjjOe1mLdulDvP2pUuJv3L3+Bs8+G558PN4BNnx66UxYRaQmxtRGYWRvgNuAzwFKg2sxmu/vCtMW+BfzS3e8ws0OAOcCAuGIqdS+/DHfdFS4ZXbcunA3893/Dl78cuk8WEYlDnI3Fo4BF7v42gJnNBE4D0hOBA12i4a7Av2KMpyTV1sLMmeEov6YmNAKfeWa4VyC9SkhEJC5xJoI+wHtp40uBIzOWmQr80cwuBToCJ8YYT0l56aVQ+D/0UDj6P+ywcB/A5Mnq2E1ECqvYl49OAu539x+Z2WjgQTM7zN3rPUTRzC4ALgDYrxW3jtbWhn5/7rordPXcoQNMnBiO/o88Ukf/IlIccSaCZUC/tPG+0bR05wFjAdz9r2ZWCfQE6j1S3N2nA9Mh3FkcV8Bx+u1vQ13/unXhxq/bbgs3fnXrVuzIRCTp4rxqqBoYaGb7m1l7YCIwO2OZd4ETAMzsYKASWBFjTEVx883hpq9168JDW668Ei6+WElAREpDbInA3bcClwBPAP8kXB20wMxuMLNx0WL/CZxvZq8ADwNTvLV1ftSIBx6Ab3wjdAgH4dGOX/tafj2IiogUgjqdi1nXrrB27a7T0zuNExGJW0OdzunO4hg98UT2JAC5O5MTESk0JYKYLF8e7gZu1y77/FZ88ZOIlBklghhs27bzCqHvfnfXTuOqqkJnciIipUCJIAY33gh/+lO4Qeyqq8KNY/37h/sE+vcP45lPFxMRKZZGG4vN7PPA7zNv8iqWUm8s/stfQpfQEyaEu4Z1k5iIlILmNhafCbxpZj8ws0EtG1p5WbUKJk0KR/133aUkICKtQ6N3Frv7l82sC1F3EGbmwH3Aw+5eG3eArYU7nHdeuE/ghRegS5fG1xERKQV5tRG4+1rgUWAmsA8wHpgbdRYnhC4jZs2C738fRmY9+RIRKU2NJgIzG2dmvwGeBdoBo9z9JGAI4c7gxJs3D/7zP+Hkk+Hyy4sdjYjI7smn07kvAje7+3PpE919g5mdF09Yrce6deH5AT17wv33Q4WuwxKRViafRDAVWJ4aMbMOwN7uvtjdn44rsNbi61+HN98Ml4v26lXsaEREdl8+x6+/AtIvHd0WTUu8n/88vL79bRgzptjRiIg0TT6JoK27b06NRMPt4wupdXjjjdCV9LHHhkQgItJa5ZMIVqR1G42ZnQZ8FF9Ipa+uLrQL7LFH6E66bbGf8yYi0gz5FGEXAjPM7KeAEZ5D/JVYoypxV10VrhSaPRv69i12NCIizZPPDWVvAZ80s07R+LrYoyphs2aFPoQuvxw+//liRyMi0nx5VWqY2SnAoUClRf0muPsNMcZVkt59F849F4YPDzeOiYiUg3xuKLuT0N/QpYSqoQlA/5jjKjlbt4aHzW/ZAjNnhvYBEZFykE9j8VHu/hVgtbv/FzAaODDesErP/feHnkXvvBMGDix2NCIiLSefRFAXvW8ws32BLYT+hhLl+eehd+9wViAiUk7yaSN4zMy6AT8E5gIO3B1nUKWoujp0JqeupUWk3DSYCMysAnja3T8G/sfMfgdUuvuaQgRXKmpr4bXXwr0DIiLlpsGqoeipZLeljW9KWhIAePnl8LyBI44odiQiIi0vnzaCp83si2bJrRSprg7vI0YUNw4RkTjkkwi+RuhkbpOZrTWzWjNbG3NcJaWmBvr1g733LnYkIiItL587izsXIpBSVl2taiERKV+NJgIzOzbb9MwH1ZSr1avhrbdg5crw0Jn99oNp02Dy5GJHJiLSMvK5fPTKtOFKYBTwEvDpWCIqMT/4QXj/+OPwvmQJXHBBGFYyEJFy0Ggbgbt/Pu31GeAwYHX8oZWGO+/cddqGDXDttYWPRUQkDk15wu5S4OCWDqRUpc4EMr37bkHDEBGJTT5tBD8h3E0MIXEMJdxhnAht2sC2bbtO32+/wsciIhKHfNoIatKGtwIPu/tfYoqnpHzwQUgC7dqFXkdTqqpCg7GISDnIJxE8CtS5+zYAM2tjZlXuviHe0IrvpZfC+ze/CQ8+GKqDdNWQiJSbvO4sBjqkjXcAnoonnNJSXR06mbvqKli8GLZvD+9KAiJSTvJJBJXpj6eMhqviC6l01NTAoEHQOfG31IlIOcsnEaw3s+GpETMbAWyML6TS4K47ikUkGfJpI7gc+JWZ/YvwqMrehEdXlrVly0Jj8ciRxY5ERCRe+fQ1VG1mg4CDokmvu/uWhtZJMbOxwH8DbYB73P37GfNvBo6PRquAvdy9W56xx6omulZKZwQiUu7yeXj914GO7v6qu78KdDKzi/NYrw3hWQYnAYcAk8zskPRl3P0Kdx/q7kOBnwC/bsJ3iEV1dbiHYMiQYkciIhKvfNoIzo+eUAaAu68Gzs9jvVHAInd/2903AzOB0xpYfhLwcB7bLYiaGjjsMOjQofFlRURas3wSQZv0h9JER/rt81ivD/Be2vjSaNouzKw/sD/wpxzzLzCzGjOrWbFiRR4f3TzuIRGoWkhEkiCfRPAH4BEzO8HMTiActT/ewnFMBB5N3bSWyd2nu/tIdx/Zq1evFv7oXb3zDqxapYZiEUmGfK4a+iZwAXBhND6fcOVQY5YB/dLG+0bTspkIfD2PbRaEGopFJEny6YZ6O/B3YDGh3v/TwD/z2HY1MNDM9jez9oTCfnbmQtEVSXsCf80/7HhVV0P79qGNQESk3OU8IzCzAwkNuJOAj4BHANz9+FzrpHP3rWZ2CfAE4fLRe919gZndANS4eyopTARmurvn2lah1dSEq4Xa59MSIiLSyjVUNfQa8DxwqrsvAjCzK3Zn4+4+B5iTMe26jPGpu7PNuG3fHjqbO/vsYkciIlIYDVUNnQ4sB54xs7ujhmJrYPmy8MYbUFurhmIRSY6cicDdZ7n7RGAQ8Ayhq4m9zOwOM/tsgeIruFRDsRKBiCRFPo3F6939IXf/POHKn5cJVxKVperq8OCZgxPzME4RSbrdemaxu6+Oruk/Ia6Aiq2mBoYNg7b5XFgrIlIGmvLw+rK1dSu8/LLuHxCRZFEiSLNwIWzcqPYBEUkWJYI0aigWkSRSIkhTXQ1dusDAgcWORESkcJQI0tTUwIgRUKG9IiIJoiIvsmkTvPKKGopFJHmUCCL/+Ads2aL2ARFJHiWCiBqKRSSplAgi1dXQowcMGFDsSERECkuJIFJTE84GrOy71RMRqU+JANiwARYsUEOxiCSTEgEwbx5s26b2ARFJJiUC1FAsIsmmREBoKN5nH+jTp9iRiIgUnhIBOxuKRUSSKPGJYO1aeP11JQIRSa7EJ4K5c8FdVwyJSHIlPhGooVhEki7xiaC6Gvr3h169ih2JiEhxJD4RqKFYRJIu0Ylg1Sp4+20lAhFJtkQnglT7gBqKRSTJlAgITyUTEUmqRCeC6urwfOJu3YodiYhI8SQ6EaihWEQkwYng/fdh6VIlAhGRxCYCNRSLiASJTgQVFTBsWLEjEREprsQmgupqOPhg6NSp2JGIiBRXIhOBuxqKRURSEpkIli6FDz9UIhARgYQmgurq8K6GYhGRhCaCmhpo2xYOP7zYkYiIFF+sicDMxprZ62a2yMyuzrHMl8xsoZktMLOH4ownpboaDjsMOnQoxKeJiJS2tnFt2MzaALcBnwGWAtVmNtvdF6YtMxC4BviUu682s73iiicl1VA8YULcnyQi0jrEeUYwCljk7m+7+2ZgJnBaxjLnA7e5+2oAd/8wxniA0O30xx+roVhEJCXORNAHeC9tfGk0Ld2BwIFm9hcz+5uZjc22ITO7wMxqzKxmxYoVzQpKDcUiIvUVu7G4LTAQGANMAu42s26ZC7n7dHcf6e4jezXzmZI1NbDHHnDooc3ajIhI2YgzESwD+qWN942mpVsKzHb3Le7+DvAGITHEproahgyB9u3j/BQRkdYjzkRQDQw0s/3NrD0wEZidscwswtkAZtaTUFX0dlwBbdsGc+eqWkhEJF1sicDdtwKXAE8A/wR+6e4LzOwGMxsXLfYEsNLMFgLPAFe6+8q4YnrjDVi3Tg3FIiLpYrt8FMDd5wBzMqZdlzbswP+JXrFTQ7GIyK6K3VhcUDU1UFUFgwYVOxIRkdKRqERQXQ3Dh0ObNsWORESkdCQmEWzZAvPmqVpIRCRTYhLBwoVQV6eGYhGRTIlJBGooFhHJLjGJoEcPOPVU+MQnih2JiEhpSUwiGD8eHnssPLBeRER2UrEoIpJwSgQiIgmnRCAiknBKBCIiCadEICKScEoEIiIJp0QgIpJwSgQiIgmnRCAiknBKBCIiCadEICKScEoEIiIJp0QgIpJwSgQiIgmnRCAiknBKBCIiCadEICKScEoEIiIJp0QgIpJwSgQiIgmnRCAiknCJSAQzZsCAAVBREd5nzCh2RCIipaNtsQOI24wZcMEFsGFDGF+yJIwDTJ5cvLhEREpF2Z8RXHvtziSQsmFDmC4iIglIBO++u3vTRUSSpuwTwX777d50EZGkKftEMG0aVFXVn1ZVFaaLiEgCEsHkyTB9OvTvD2bhffp0NRSLiKSU/VVDEAp9FfwiItnFekZgZmPN7HUzW2RmV2eZP8XMVpjZvOj173HGIyIiu4rtjMDM2gC3AZ8BlgLVZjbb3RdmLPqIu18SVxwiItKwOM8IRgGL3P1td98MzAROi/HzRESkCeJMBH2A99LGl0bTMn3RzOab2aNm1i/bhszsAjOrMbOaFStWxBGriEhiFfuqoceAAe5+OPAk8EC2hdx9uruPdPeRvXr1KmiAIiLlLs6rhpYB6Uf4faNpO7j7yrTRe4AfNLbRl1566SMzW9IiEba8nsBHxQ6iAYqveUo9Pij9GBVf8zQnvv65ZsSZCKqBgWa2PyEBTATOSl/AzPZx9+XR6Djgn41t1N1L9pTAzGrcfWSx48hF8TVPqccHpR+j4mueuOKLLRG4+1YzuwR4AmgD3OvuC8zsBqDG3WcDl5nZOGArsAqYElc8IiKSXaw3lLn7HGBOxrTr0oavAa6JMwYREWlYsRuLy830YgfQCMXXPKUeH5R+jIqveWKJz9w9ju2KiEgroTMCEZGEUyIQEUk4JYLdZGb9zOwZM1toZgvM7D+yLDPGzNakdaZ3XbZtxRjjYjP7R/TZNVnmm5ndGnUGON/MhhcwtoPS9ss8M1trZpdnLFPw/Wdm95rZh2b2atq07mb2pJm9Gb3vmWPdc6Jl3jSzcwoU2w/N7LXo7/cbM+uWY90GfwsxxzjVzJal/R1PzrFug51TxhjfI2mxLTazeTnWjXUf5ipTCvr7c3e9duMF7AMMj4Y7A28Ah2QsMwb4XRFjXAz0bGD+ycDjgAGfBP5epDjbAO8D/Yu9/4BjgeHAq2nTfgBcHQ1fDdyYZb3uwNvR+57R8J4FiO2zQNto+MZsseXzW4g5xqnAN/L4DbwFHAC0B17J/H+KK76M+T8CrivGPsxVphTy96czgt3k7svdfW40XEu4CS5bH0ql7DTg5x78DehmZvsUIY4TgLfcveh3irv7c4R7WdKdxs5uTx4AvpBl1c8BT7r7KndfTegqZWzcsbn7H919azT6N8Kd+0WTY//loyCdUzYUn5kZ8CXg4Zb+3Hw0UKYU7PenRNAMZjYAGAb8Pcvs0Wb2ipk9bmaHFjYyHPijmb1kZhdkmZ9vh4Bxm0juf75i7r+UvX3nne/vA3tnWaYU9uW5hDO8bBr7LcTtkqj66t4cVRulsP+OAT5w9zdzzC/YPswoUwr2+1MiaCIz6wT8D3C5u6/NmD2XUN0xBPgJMKvA4R3t7sOBk4Cvm9mxBf78RplZe0K3Ir/KMrvY+28XHs7DS+5aazO7lnBn/owcixTzt3AH8AlgKLCcUP1SiibR8NlAQfZhQ2VK3L8/JYImMLN2hD/YDHf/deZ8d1/r7uui4TlAOzPrWaj43H1Z9P4h8BvC6Xe6RjsELICTgLnu/kHmjGLvvzQfpKrMovcPsyxTtH1pZlOAU4HJUUGxizx+C7Fx9w/cfZu7bwfuzvHZRf0tmllb4HTgkVzLFGIf5ihTCvb7UyLYTVF94s+Af7r7j3Ms0ztaDjMbRdjPK7MtG0N8Hc2sc2qY0Kj4asZis4GvWPBJYE3aKWih5DwKK+b+yzAbSF2FcQ7w2yzLPAF81sz2jKo+PhtNi5WZjQWuAsa5+4Ycy+TzW4gzxvR2p/E5PntH55TRWeJEwn4vlBOB19x9abaZhdiHDZQphfv9xdUSXq4v4GjCKdp8YF70Ohm4ELgwWuYSYAHhCoi/AUcVML4Dos99JYrh2mh6enxGeIzoW8A/gJEF3ocdCQV717RpRd1/hKS0HNhCqGc9D+gBPA28CTwFdI+WHQnck7buucCi6PXVAsW2iFA3nPoN3hktuy8wp6HfQgH334PR72s+oVDbJzPGaPxkwpUyb8UVY7b4oun3p353acsWdB82UKYU7PenLiZERBJOVUMiIgmnRCAiknBKBCIiCadEICKScEoEIiIJp0QgEjGzbVa/Z9QW6wnTzAak93wpUkpifWaxSCuz0d2HFjsIkULTGYFII6L+6H8Q9Un/opn9WzR9gJn9KepU7Wkz2y+avreFZwS8Er2OijbVxszujvqc/6OZdYiWvyzqi36+mc0s0teUBFMiENmpQ0bV0Jlp89a4+2Dgp8At0bSfAA+4++GETt9ujabfCvzZQ6d5wwl3pAIMBG5z90OBj4EvRtOvBoZF27kwnq8mkpvuLBaJmNk6d++UZfpi4NPu/nbUOdj77t7DzD4idJuwJZq+3N17mtkKoK+7b0rbxgBCv/EDo/FvAu3c/btm9gdgHaGX1VkedbgnUig6IxDJj+cY3h2b0oa3sbON7hRC30/DgeqoR0yRglEiEMnPmWnvf42GXyD0lgkwGXg+Gn4auAjAzNqYWddcGzWzCqCfuz8DfBPoCuxyViISJx15iOzUweo/wPwP7p66hHRPM5tPOKqfFE27FLjPzK4EVgBfjab/BzDdzM4jHPlfROj5Mps2wC+iZGHAre7+cQt9H5G8qI1ApBFRG8FId/+o2LGIxEFVQyIiCaczAhGRhNMZgYhIwikRiIgknBKBiEjCKRGIiCScEoGISML9f2Q4L0QPizC8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690f435",
   "metadata": {},
   "source": [
    "$ mkdir -p ~/aiffel/sentiment_classification/data\n",
    "\n",
    "$ pip list | grep gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b1fac89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38cf24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07f2c01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04136419, -0.04826828, -0.03455997,  0.12462887, -0.03266156,\n",
       "       -0.02556084, -0.03718455, -0.01925711, -0.03047885, -0.02174778,\n",
       "       -0.0403543 ,  0.03666817, -0.02445058, -0.02696768, -0.02018016,\n",
       "       -0.03403134], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "953c2c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mysterious', 0.9852046370506287),\n",
       " ('brothers', 0.9836002588272095),\n",
       " ('popcorn', 0.9831486344337463),\n",
       " ('manner', 0.9810843467712402),\n",
       " ('certainly', 0.9804835319519043),\n",
       " ('contrived', 0.9801706075668335),\n",
       " ('animals', 0.9796610474586487),\n",
       " ('haunted', 0.9794566631317139),\n",
       " ('water', 0.9778841137886047),\n",
       " ('oil', 0.9777358770370483)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbaf0fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be21227b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "790ceee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23461e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46546a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 22s 198ms/step - loss: 0.6905 - accuracy: 0.5007 - val_loss: 0.6806 - val_accuracy: 0.5627\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 5s 152ms/step - loss: 0.6435 - accuracy: 0.6427 - val_loss: 0.5902 - val_accuracy: 0.7074\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 5s 153ms/step - loss: 0.4741 - accuracy: 0.7969 - val_loss: 0.3852 - val_accuracy: 0.8390\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 5s 154ms/step - loss: 0.3008 - accuracy: 0.8807 - val_loss: 0.3094 - val_accuracy: 0.8695\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 5s 156ms/step - loss: 0.2166 - accuracy: 0.9165 - val_loss: 0.3128 - val_accuracy: 0.8678\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 5s 156ms/step - loss: 0.1583 - accuracy: 0.9485 - val_loss: 0.2919 - val_accuracy: 0.8811\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 5s 157ms/step - loss: 0.1155 - accuracy: 0.9689 - val_loss: 0.2952 - val_accuracy: 0.8827\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 5s 155ms/step - loss: 0.0847 - accuracy: 0.9801 - val_loss: 0.3057 - val_accuracy: 0.8814\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 5s 154ms/step - loss: 0.0612 - accuracy: 0.9905 - val_loss: 0.3319 - val_accuracy: 0.8760\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 5s 153ms/step - loss: 0.0423 - accuracy: 0.9954 - val_loss: 0.3388 - val_accuracy: 0.8799\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 5s 153ms/step - loss: 0.0318 - accuracy: 0.9972 - val_loss: 0.3493 - val_accuracy: 0.8806\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 5s 153ms/step - loss: 0.0201 - accuracy: 0.9987 - val_loss: 0.3787 - val_accuracy: 0.8801\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 5s 151ms/step - loss: 0.0136 - accuracy: 0.9991 - val_loss: 0.4023 - val_accuracy: 0.8794\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 4s 151ms/step - loss: 0.0096 - accuracy: 0.9993 - val_loss: 0.4363 - val_accuracy: 0.8735\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 4s 149ms/step - loss: 0.0068 - accuracy: 0.9995 - val_loss: 0.4486 - val_accuracy: 0.8757\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 5s 151ms/step - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.4588 - val_accuracy: 0.8778\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 5s 151ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.4704 - val_accuracy: 0.8779\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 5s 151ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.4833 - val_accuracy: 0.8773\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 5s 152ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.4960 - val_accuracy: 0.8762\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 4s 141ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.5091 - val_accuracy: 0.8766\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aae659a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.5599 - accuracy: 0.8666\n",
      "[0.559887707233429, 0.8666399717330933]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9a407e",
   "metadata": {},
   "source": [
    "$ ln -s ~/data/*.txt ~/aiffel/sentiment_classification/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ea30bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "0.5.2\n",
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import konlpy\n",
    "import gensim\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fa1737",
   "metadata": {},
   "source": [
    "1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "194fafaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# 데이터를 읽어봅시다. \n",
    "home_path = os.getenv('HOME')\n",
    "train_data = pd.read_table(home_path+'/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table(home_path+'/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc739f7",
   "metadata": {},
   "source": [
    "2) 데이터 로더 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e354449e",
   "metadata": {},
   "source": [
    "실습 때 다루었던 IMDB 데이터셋은 텍스트를 가공하여 imdb.data_loader() 메서드를 호출하면 숫자 인덱스로 변환된 텍스트와 word_to_index 딕셔너리까지 친절하게 제공합니다. 그러나 이번에 다루게 될 nsmc 데이터셋은 전혀 가공되지 않은 텍스트 파일로 이루어져 있습니다. 이것을 읽어서 imdb.data_loader()와 동일하게 동작하는 자신만의 data_loader를 만들어 보는 것으로 시작합니다. data_loader 안에서는 다음을 수행해야 합니다.\n",
    "\n",
    "- 데이터의 중복 제거\n",
    "- NaN 결측치 제거\n",
    "- 한국어 토크나이저로 토큰화\n",
    "- 불용어(Stopwords) 제거\n",
    "- 사전word_to_index 구성\n",
    "- 텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "- X_train, y_train, X_test, y_test, word_to_index 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "120dd7f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2819192930.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_31/2819192930.py\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=num_words):\n",
    "    # [[YOUR CODE]]\n",
    "    train_data.\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63415c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
