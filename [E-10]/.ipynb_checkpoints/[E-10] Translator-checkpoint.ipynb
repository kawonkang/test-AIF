{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "016b527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b8fb02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 217975\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142404</th>\n",
       "      <td>Don't worry. I'll fix everything.</td>\n",
       "      <td>Ne t'inquiète pas. Je vais tout arranger.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22502</th>\n",
       "      <td>This way, please.</td>\n",
       "      <td>Par ici, s'il vous plait.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9383</th>\n",
       "      <td>Tom struggled.</td>\n",
       "      <td>Tom s'est débattu.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86871</th>\n",
       "      <td>I arrived late last night.</td>\n",
       "      <td>Je suis arrivé tard la nuit dernière.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193523</th>\n",
       "      <td>Can I have two hamburgers and a coke, please?</td>\n",
       "      <td>Puis-je avoir deux hamburgers et un coca, s'il...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  eng  \\\n",
       "142404              Don't worry. I'll fix everything.   \n",
       "22502                               This way, please.   \n",
       "9383                                   Tom struggled.   \n",
       "86871                      I arrived late last night.   \n",
       "193523  Can I have two hamburgers and a coke, please?   \n",
       "\n",
       "                                                      fra  \\\n",
       "142404          Ne t'inquiète pas. Je vais tout arranger.   \n",
       "22502                           Par ici, s'il vous plait.   \n",
       "9383                                   Tom s'est débattu.   \n",
       "86871               Je suis arrivé tard la nuit dernière.   \n",
       "193523  Puis-je avoir deux hamburgers et un coca, s'il...   \n",
       "\n",
       "                                                       cc  \n",
       "142404  CC-BY 2.0 (France) Attribution: tatoeba.org #7...  \n",
       "22502   CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "9383    CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "86871   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "193523  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.getenv('HOME') + '/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng','fra','cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :', len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24ed013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>You're a pig.</td>\n",
       "      <td>Tu es un porc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35375</th>\n",
       "      <td>This one is for us.</td>\n",
       "      <td>Celui-ci est pour nous.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12898</th>\n",
       "      <td>Tom is spoiled.</td>\n",
       "      <td>Tom est gâté.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40234</th>\n",
       "      <td>I'll show you later.</td>\n",
       "      <td>Je vous montrerai plus tard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>Tom'll quit.</td>\n",
       "      <td>Tom va arrêter.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        eng                           fra\n",
       "6758          You're a pig.                Tu es un porc.\n",
       "35375   This one is for us.       Celui-ci est pour nous.\n",
       "12898       Tom is spoiled.                 Tom est gâté.\n",
       "40234  I'll show you later.  Je vous montrerai plus tard.\n",
       "4174           Tom'll quit.               Tom va arrêter."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng','fra']][:50000]\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38479373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26242</th>\n",
       "      <td>I never loved you.</td>\n",
       "      <td>\\t Je ne t'ai jamais aimée. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12090</th>\n",
       "      <td>Many fish died.</td>\n",
       "      <td>\\t Beaucoup de poissons ont péri. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26216</th>\n",
       "      <td>I need some light.</td>\n",
       "      <td>\\t J'ai besoin de lumière. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27736</th>\n",
       "      <td>Protect your eyes.</td>\n",
       "      <td>\\t Protège tes yeux. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32395</th>\n",
       "      <td>I hate this carpet.</td>\n",
       "      <td>\\t Je déteste ce tapis. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng                                   fra\n",
       "26242   I never loved you.        \\t Je ne t'ai jamais aimée. \\n\n",
       "12090      Many fish died.  \\t Beaucoup de poissons ont péri. \\n\n",
       "26216   I need some light.         \\t J'ai besoin de lumière. \\n\n",
       "27736   Protect your eyes.               \\t Protège tes yeux. \\n\n",
       "32395  I hate this carpet.            \\t Je déteste ce tapis. \\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sos_token = '\\t'\n",
    "eos_token = '\\n'\n",
    "lines.fra = lines.fra.apply(lambda x : '\\t ' + x + ' \\n')\n",
    "print('전체 샘플의 수 :', len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd05905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[19, 4, 7], [19, 4, 7], [19, 4, 7]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(char_level=True) # 문자 단위로 Tokenizer를 생성\n",
    "eng_tokenizer.fit_on_texts(lines.eng) # 50000개의 행을 가진 eng의 각 행에 토큰화를 수행\n",
    "input_text = eng_tokenizer.texts_to_sequences(lines.eng) # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d99651f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 1, 19, 5, 1, 31, 1, 11],\n",
       " [10, 1, 15, 5, 12, 16, 29, 2, 14, 1, 11],\n",
       " [10, 1, 2, 7, 1, 12, 9, 8, 4, 2, 1, 31, 1, 11]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer(char_level=True)\n",
    "fra_tokenizer.fit_on_texts(lines.fra)\n",
    "target_text = fra_tokenizer.texts_to_sequences(lines.fra)\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8351a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 52\n",
      "프랑스어 단어장의 크기 : 73\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7857c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 21\n",
      "프랑스어 시퀀스의 최대 길이 69\n"
     ]
    }
   ],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaf391c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 50000\n",
      "영어 단어장의 크기 : 52\n",
      "프랑스어 단어장의 크기 : 73\n",
      "영어 시퀀스의 최대 길이 21\n",
      "프랑스어 시퀀스의 최대 길이 69\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0eccec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "# 시작 토큰 제거\n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01f2f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (50000, 21)\n",
      "프랑스어 입력데이터의 크기(shape) : (50000, 69)\n",
      "프랑스어 출력데이터의 크기(shape) : (50000, 69)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08519d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19  4  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7655e150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (50000, 21, 52)\n",
      "프랑스어 입력데이터의 크기(shape) : (50000, 69, 73)\n",
      "프랑스어 출력데이터의 크기(shape) : (50000, 69, 73)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7de402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (50000, 21, 52)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (50000, 69, 73)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (50000, 69, 73)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dcb9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72bbc395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 텐서 생성.\n",
    "encoder_inputs = Input(shape=(None, eng_vocab_size))\n",
    "# hidden size가 256인 인코더의 LSTM 셀 생성\n",
    "encoder_lstm = LSTM(units = 256, return_state = True)\n",
    "# 디코더로 전달할 hidden state, cell state를 리턴. encoder_outputs은 여기서는 불필요.\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도 저장.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "942c7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 텐서 생성.\n",
    "decoder_inputs = Input(shape=(None, fra_vocab_size))\n",
    "# hidden size가 256인 인코더의 LSTM 셀 생성\n",
    "decoder_lstm = LSTM(units = 256, return_sequences = True, return_state=True)\n",
    "# decoder_outputs는 모든 time step의 hidden state\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63166684",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e94dda3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 52)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 73)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 316416      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  337920      input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 73)     18761       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 673,097\n",
      "Trainable params: 673,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf549fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "368/368 [==============================] - 36s 19ms/step - loss: 0.9515 - val_loss: 0.8029\n",
      "Epoch 2/50\n",
      "368/368 [==============================] - 6s 16ms/step - loss: 0.5763 - val_loss: 0.6765\n",
      "Epoch 3/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.4768 - val_loss: 0.6078\n",
      "Epoch 4/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.4194 - val_loss: 0.5255\n",
      "Epoch 5/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.3814 - val_loss: 0.4911\n",
      "Epoch 6/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.3537 - val_loss: 0.4612\n",
      "Epoch 7/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.3323 - val_loss: 0.4434\n",
      "Epoch 8/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.3152 - val_loss: 0.4378\n",
      "Epoch 9/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.3013 - val_loss: 0.4179\n",
      "Epoch 10/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2894 - val_loss: 0.4130\n",
      "Epoch 11/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2792 - val_loss: 0.3983\n",
      "Epoch 12/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2702 - val_loss: 0.3932\n",
      "Epoch 13/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2621 - val_loss: 0.3919\n",
      "Epoch 14/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2549 - val_loss: 0.3836\n",
      "Epoch 15/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2483 - val_loss: 0.3816\n",
      "Epoch 16/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2421 - val_loss: 0.3798\n",
      "Epoch 17/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2366 - val_loss: 0.3788\n",
      "Epoch 18/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2313 - val_loss: 0.3787\n",
      "Epoch 19/50\n",
      "368/368 [==============================] - 6s 18ms/step - loss: 0.2264 - val_loss: 0.3796\n",
      "Epoch 20/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2217 - val_loss: 0.3737\n",
      "Epoch 21/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2175 - val_loss: 0.3714\n",
      "Epoch 22/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2132 - val_loss: 0.3736\n",
      "Epoch 23/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2094 - val_loss: 0.3761\n",
      "Epoch 24/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2057 - val_loss: 0.3725\n",
      "Epoch 25/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.2021 - val_loss: 0.3734\n",
      "Epoch 26/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1986 - val_loss: 0.3746\n",
      "Epoch 27/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1954 - val_loss: 0.3755\n",
      "Epoch 28/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1923 - val_loss: 0.3768\n",
      "Epoch 29/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1892 - val_loss: 0.3768\n",
      "Epoch 30/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1864 - val_loss: 0.3797\n",
      "Epoch 31/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1836 - val_loss: 0.3874\n",
      "Epoch 32/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1808 - val_loss: 0.3842\n",
      "Epoch 33/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1783 - val_loss: 0.3825\n",
      "Epoch 34/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1758 - val_loss: 0.3898\n",
      "Epoch 35/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1734 - val_loss: 0.3896\n",
      "Epoch 36/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1710 - val_loss: 0.3910\n",
      "Epoch 37/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1688 - val_loss: 0.3904\n",
      "Epoch 38/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1664 - val_loss: 0.3961\n",
      "Epoch 39/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1643 - val_loss: 0.3957\n",
      "Epoch 40/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1622 - val_loss: 0.3984\n",
      "Epoch 41/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1603 - val_loss: 0.3975\n",
      "Epoch 42/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1583 - val_loss: 0.4083\n",
      "Epoch 43/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1564 - val_loss: 0.4106\n",
      "Epoch 44/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1544 - val_loss: 0.4083\n",
      "Epoch 45/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1527 - val_loss: 0.4156\n",
      "Epoch 46/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1508 - val_loss: 0.4187\n",
      "Epoch 47/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1493 - val_loss: 0.4123\n",
      "Epoch 48/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1476 - val_loss: 0.4189\n",
      "Epoch 49/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1460 - val_loss: 0.4234\n",
      "Epoch 50/50\n",
      "368/368 [==============================] - 6s 17ms/step - loss: 0.1444 - val_loss: 0.4244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f8e7aee20>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2945cc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 52)]        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 256), (None, 256) 316416    \n",
      "=================================================================\n",
      "Total params: 316,416\n",
      "Trainable params: 316,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46b6a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 time step의 hidden state를 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "# 이전 time step의 cell state를 저장하는 텐서\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
    "# 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_states_inputs)\n",
    "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8894a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, 73)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  337920      input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 73)     18761       lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 356,681\n",
      "Trainable params: 356,681\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c15e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48ba5f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, fra_vocab_size))\n",
    "    target_seq[0, 0, fra2idx['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1, fra_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bca0e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Go.\n",
      "정답 문장:  Bouge ! \n",
      "번역기가 번역한 문장:  va ! \n",
      "-----------------------------------\n",
      "입력 문장: Hello!\n",
      "정답 문장:  Bonjour ! \n",
      "번역기가 번역한 문장:  salut ! \n",
      "-----------------------------------\n",
      "입력 문장: Got it!\n",
      "정답 문장:  Compris ! \n",
      "번역기가 번역한 문장:  appelez-vous ! \n",
      "-----------------------------------\n",
      "입력 문장: Goodbye.\n",
      "정답 문장:  Au revoir. \n",
      "번역기가 번역한 문장:  au revoir. \n",
      "-----------------------------------\n",
      "입력 문장: Hands off.\n",
      "정답 문장:  Pas touche ! \n",
      "번역기가 번역한 문장:  recule ! \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스 (자유롭게 선택해 보세요)\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.eng[seq_index])\n",
    "    print('정답 문장:', lines.fra[seq_index][1:len(lines.fra[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd99225",
   "metadata": {},
   "source": [
    "### 루브릭\n",
    "\n",
    "#### 1. 번역기 모델 학습에 필요한 텍스트 데이터 전처리가 잘 이루어졌다.\t\n",
    "\n",
    "- 구두점, 대소문자, 띄어쓰기 등 번역기 모델에 요구되는 전처리가 정상적으로 진행되었다.\n",
    "\n",
    "#### 2. seq2seq 기반의 번역기 모델이 정상적으로 구동된다.\t\n",
    "\n",
    "- seq2seq 모델 훈련결과를 그래프로 출력해보고, validation loss그래프가 우하향하는 경향성을 보이며 학습이 진행됨이 확인되었다.\n",
    "\n",
    "#### 3. 테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.\t\n",
    "\n",
    "- 테스트용 디코더 모델이 정상적으로 만들어졌으며, input(영어)와 output(프랑스어) 모두 한글로 번역해서 결과를 출력해보았고, 둘의 내용이 유사함을 확인하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01eed67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13508e5b",
   "metadata": {},
   "source": [
    "### Step 1. 정제, 정규화, 전처리 (영어, 프랑스어 모두!)\n",
    "\n",
    "글자 단위가 아닌 단어 단위의 번역기를 하기 위해서는 글자 단위에서는 신경쓰지 않았던 몇 가지 추가적인 전처리가 필요합니다.\n",
    "\n",
    "1. 구두점(Punctuation)을 단어와 분리해주세요.\n",
    "\n",
    "> 일반적으로 영어권 언어의 경우에는 띄어쓰기 단위로 단어를 분리합니다. 토큰화(Tokenization) 라고도 불리는 이 작업은 어디서부터 어디까지가 하나의 단어인지를 구분하는 작업인데요, 그런데 띄어쓰기를 해주기 전에 구두점을 분리하는 작업이 필요할 때가 있습니다.\n",
    "> \n",
    "> 예를 들어서 'he is a good boy!'라는 문장이 있을 때, 이를 띄어쓰기 단위로 토큰화한다면 ['he', 'is', 'a', 'good', 'boy!']가 됩니다. 그런데 실제로 !는 boy와 붙어있는 한 단어가 아니므로 좀 더 올바른 전처리는 ['he', 'is', 'a', 'good', 'boy', '!']가 맞습니다.\n",
    "!나 ? 또는 온점과 같은 특수문자들을 구두점(punctuation)이라고 부릅니다. 이들을 토큰화하기 전에 단어와 미리 분리시켜주세요!\n",
    "> \n",
    "> - 분리 전 : he is a Good boy!\n",
    "> - 분리 후 : he is a Good boy !\n",
    "\n",
    "2. 소문자로 바꿔주세요.\n",
    "\n",
    "> 기계가 보기에는 스펠링이 같더라도 대문자로 된 단어와 소문자로 된 단어는 서로 다른 단어입니다. 예를 들어 'Good'과 'good'은 기계가 보기에는 다른 단어입니다. 그래서 모든 문장에 대해서 전부 영어로 바꿔주는 작업을 하겠습니다.\n",
    "> \n",
    "> - 변환 전 : he is a Good boy !\n",
    "> - 변환 후 : he is a good boy !\n",
    "\n",
    "3. 띄어쓰기 단위로 토큰화를 수행하세요.\n",
    "\n",
    "> 띄어쓰기 단위로 토큰화를 수행해서 단어를 분리하는 작업을 해주세요. 기계는 이렇게 분리된 토큰들을 각각 하나의 단어로 인식할 수 있게 됩니다.\n",
    "> \n",
    "> - 토큰화 전 : 'he is a good boy !'\n",
    "> - 토큰화 후 : ['he', 'is', 'a', 'good', 'boy', '!']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1897a2",
   "metadata": {},
   "source": [
    "### Step 2. 디코더의 문장에 시작 토큰과 종료 토큰을 넣어주세요.\n",
    "\n",
    "글자 단위 번역기를 구현할 때와 마찬가지로 디코더의 입력 시퀀스 맨 앞에는 시작을 의미하는 토큰인 <sos>가 필요합니다. 그리고 교사 강요를 수행할 때, 디코더의 실제값이 되는 디코더의 레이블 시퀀스에는 종료를 의미하는 종료 토큰 <eos>가 필요합니다.\n",
    "예를 들어 번역 문장이 \"Courez!\" 였다고 한다면, Step 1을 거친 후에는 다음과 같은 결과를 얻습니다.\n",
    "\n",
    "- Step 1을 수행한 후 : ['courez', '!']\n",
    "    \n",
    "이 문장에 대해서 각각 디코더의 입력 시퀀스와 레이블 시퀀스를 만들면 다음과 같습니다.\n",
    "\n",
    "- 입력 시퀀스 : ['<sos>', 'courez', '!']\n",
    "    \n",
    "- 레이블 시퀀스 : ['courez', '!', '<eos>']\n",
    "    \n",
    "참고로 Step 2가 반드시 Step 1이 끝난 후에 이루어질 필요는 없습니다!\n",
    "Step 1을 수행하는 중간에 수행해도 상관없습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f1e9e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 217975\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172205</th>\n",
       "      <td>Is the movie theater near the station?</td>\n",
       "      <td>Le cinéma est-il proche de la gare ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>My head really hurts.</td>\n",
       "      <td>J'ai très mal à la tête.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116438</th>\n",
       "      <td>That doesn't mean I can stay.</td>\n",
       "      <td>Ça ne signifie pas que je puis rester.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39279</th>\n",
       "      <td>I had a hectic week.</td>\n",
       "      <td>J'ai eu une semaine mouvementée.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31758</th>\n",
       "      <td>He skipped a grade.</td>\n",
       "      <td>Il a sauté une classe.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           eng  \\\n",
       "172205  Is the movie theater near the station?   \n",
       "48837                    My head really hurts.   \n",
       "116438           That doesn't mean I can stay.   \n",
       "39279                     I had a hectic week.   \n",
       "31758                      He skipped a grade.   \n",
       "\n",
       "                                           fra  \\\n",
       "172205    Le cinéma est-il proche de la gare ?   \n",
       "48837                 J'ai très mal à la tête.   \n",
       "116438  Ça ne signifie pas que je puis rester.   \n",
       "39279         J'ai eu une semaine mouvementée.   \n",
       "31758                   Il a sauté une classe.   \n",
       "\n",
       "                                                       cc  \n",
       "172205  CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "48837   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "116438  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "39279   CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "31758   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0848807a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67695</th>\n",
       "      <td>Why is my dog growling?</td>\n",
       "      <td>Pourquoi mon chien grogne-t-il ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70045</th>\n",
       "      <td>I can do that in a week.</td>\n",
       "      <td>Je peux le faire en une semaine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61878</th>\n",
       "      <td>How is that pronounced?</td>\n",
       "      <td>Comment ça se prononce ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67048</th>\n",
       "      <td>We're college students.</td>\n",
       "      <td>Nous sommes étudiants.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77554</th>\n",
       "      <td>Get a good night's sleep.</td>\n",
       "      <td>Passez une bonne nuit de sommeil.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             eng                                fra\n",
       "67695    Why is my dog growling?   Pourquoi mon chien grogne-t-il ?\n",
       "70045   I can do that in a week.   Je peux le faire en une semaine.\n",
       "61878    How is that pronounced?           Comment ça se prononce ?\n",
       "67048    We're college students.             Nous sommes étudiants.\n",
       "77554  Get a good night's sleep.  Passez une bonne nuit de sommeil."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][60000:93000] # 5만개 샘플 사용\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b8f53e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['You were there, right?', 'You will stay at home.',\n",
       "       \"You won't be punished.\", ..., 'What time did you wake up?',\n",
       "       'What time did you wake up?', 'What time did you wake up?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#영어와 프랑스어 분리하기\n",
    "lines_np_eng= lines['eng'].to_numpy()\n",
    "lines_np_fra= lines['fra'].to_numpy()\n",
    "lines_np_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "230d571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = '<start> '\n",
    "eos_token = ' <end>'\n",
    "\n",
    "\n",
    "def preprocess(line, plus_token = True):\n",
    "    #소문자로 변경하기\n",
    "    line = line.lower().strip()\n",
    "    #구두점 분리하기\n",
    "    line = re.sub(r\"([?.!,¿])\", r\" \\1 \", line)\n",
    "    line = re.sub(r'[\" \"]+', \" \", line)\n",
    "    line = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", line)\n",
    "    \n",
    "    line = line.strip()\n",
    "    \n",
    "    if plus_token == True:\n",
    "        line = sos_token + line + eos_token\n",
    "        \n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78934c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_lines = []\n",
    "fra_lines = []\n",
    "\n",
    "for eng, fra in zip(lines.eng, lines.fra):\n",
    "    if len(eng) == 0: continue\n",
    "    if len(fra) == 0: continue\n",
    "        \n",
    "    eng_lines.append(preprocess(eng, plus_token=False))\n",
    "    fra_lines.append(preprocess(fra))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c809c673",
   "metadata": {},
   "source": [
    "### Step 3. 케라스의 토크나이저로 텍스트를 숫자로 바꿔보세요.\n",
    "\n",
    "딥러닝 모델은 텍스트가 아닌 숫자를 처리합니다. 케라스 토크나이저를 사용해서 각 단어를 고유한 정수로 바꿔보세요.\n",
    "케라스 토크나이저의 사용법은 아래의 링크에서 2. 케라스(Keras)의 텍스트 전처리에 설명되어 있습니다.\n",
    "\n",
    "- 위키독스\n",
    "\n",
    "위 링크의 가이드를 통해서 영어와 프랑스어에 대한 토크나이저를 각각 생성하고, tokenizer.texts_to_sequences()를 사용하여 모든 샘플에 대해서 정수 시퀀스로 변환해보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fdce5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#토큰화 함수\n",
    "def tokenize(corpus):\n",
    "    tokenizer = Tokenizer(num_words=7000,\n",
    "                         filters=' ',\n",
    "                         oov_token='<unk>')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    \n",
    "    return tensor, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1837369e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(eng_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28e06cf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 15, 105, 23, 374, 34, 19, 7, 22, 8, 6, 3],\n",
       " [2, 15, 3036, 151, 78, 4, 3],\n",
       " [2, 15, 13, 1135, 8, 3723, 4, 3],\n",
       " [2, 10, 19, 347, 8, 16, 1519, 4, 3],\n",
       " [2, 15, 13, 389, 8, 16, 1519, 4, 3],\n",
       " [2, 10, 19, 1647, 8, 17, 4, 3],\n",
       " [2, 15, 443, 176, 9, 5098, 4, 3],\n",
       " [2, 15, 443, 176, 9, 35, 20, 128, 278, 4, 3],\n",
       " [2, 15, 443, 176, 9, 26, 841, 72, 4, 3],\n",
       " [2, 10, 1136, 176, 9, 10, 841, 72, 4, 3]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tensor, eng_tokenizer = tokenize(eng_lines)\n",
    "fra_tensor, fra_tokenizer = tokenize(fra_lines)\n",
    "fra_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e2ae32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = eng_tensor\n",
    "#종료 토큰 제거\n",
    "decoder_input = [[char for char in line if char != fra_tokenizer.word_index['<end>']] for line in fra_tensor]\n",
    "decoder_target = [[char for char in line if char != fra_tokenizer.word_index['<start>']] for line in fra_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9433f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(tensor):\n",
    "    total_data_text = list(tensor)\n",
    "    num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "    max_tokens = max(num_tokens)\n",
    "    maxlen = int(max_tokens)\n",
    "    tensor = pad_sequences(tensor, padding='post', maxlen=maxlen)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c7697a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기 :  (33000, 10)\n",
      "프랑스어 입력데이터의 크기 :  (33000, 17)\n",
      "프랑스어 출력데이터의 크기 :  (33000, 17)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_tensor(encoder_input)\n",
    "decoder_input = pad_tensor(decoder_input)\n",
    "decoder_target = pad_tensor(decoder_target)\n",
    "print('영어 데이터의 크기 : ', encoder_input.shape)\n",
    "print('프랑스어 입력데이터의 크기 : ', decoder_input.shape)\n",
    "print('프랑스어 출력데이터의 크기 : ', decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "716c8268",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index)+1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index)+1\n",
    "\n",
    "max_eng_seq_len = encoder_input.shape[1]\n",
    "max_fra_seq_len = decoder_input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8799b770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 5795\n",
      "프랑스어 단어장의 크기 : 8297\n",
      "영어 시퀀스의 최대 길이 : 10\n",
      "프랑스어 시퀀스의 최대 길이 : 17\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이 :', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이 :', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a864a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48f07017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (30000, 10)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (30000, 17)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (30000, 17)\n",
      "영어 학습데이터의 크기(shape) : (3000, 10)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (3000, 17)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (3000, 17)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :', encoder_input_train.shape)\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',decoder_input_train.shape)\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',decoder_target_train.shape)\n",
    "print('영어 학습데이터의 크기(shape) :', encoder_input_test.shape)\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',decoder_input_test.shape)\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de480ac",
   "metadata": {},
   "source": [
    "### Step 4. 임베딩 층(Embedding layer) 사용하기\n",
    "\n",
    "이번에는 입력이 되는 각 단어를 임베딩 층을 사용하여 벡터화하겠습니다.\n",
    "임베딩 층을 사용하는 방법과 그 설명에 대해서는 아래의 링크의 1. 케라스 임베딩 층(Keras Embedding layer) 을 참고하세요.\n",
    "\n",
    "실제 번역기 구현을 위해서 사용할 수 있는 인코더 코드의 예시는 다음과 같습니다. 이를 통해서 인코더와 디코더의 임베딩 층을 각각 구현해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5beeb4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 1024\n",
    "hidden_size = 1024\n",
    "\n",
    "encoder_inputs = Input(shape=(None, ), name='encoder_input')\n",
    "enc_emb = Embedding(eng_vocab_size, embedding_size, input_length=max_eng_seq_len)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(hidden_size, dropout=0.6, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "323be41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, ), name='decoder_input')\n",
    "dec_emb = Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "decoder_lstm = LSTM(hidden_size, dropout=0.6, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "594cf1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "233ea2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13c87458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 1024)   5934080     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 1024)   8496128     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 1024)   0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 1024)   0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 1024), (None 8392704     masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 1024), 8392704     masking_1[0][0]                  \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 8297)   8504425     lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 8297)   68848506    dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 108,568,547\n",
      "Trainable params: 108,568,547\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db20ede3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 138s 139ms/step - loss: 7.5234 - val_loss: 6.1711\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 129s 138ms/step - loss: 5.1218 - val_loss: 4.2265\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 129s 138ms/step - loss: 3.6721 - val_loss: 3.3393\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 3.1022 - val_loss: 2.7758\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 2.5818 - val_loss: 2.4296\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 2.3334 - val_loss: 2.2608\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 2.1950 - val_loss: 2.1559\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 2.1089 - val_loss: 2.0870\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 2.0339 - val_loss: 2.0135\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.9619 - val_loss: 1.9529\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.8967 - val_loss: 1.9043\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.8398 - val_loss: 1.8542\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.7899 - val_loss: 1.8141\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.7465 - val_loss: 1.7800\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.7054 - val_loss: 1.7499\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.6661 - val_loss: 1.7221\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.6286 - val_loss: 1.6921\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.5929 - val_loss: 1.6663\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.5584 - val_loss: 1.6416\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.5254 - val_loss: 1.6225\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.4945 - val_loss: 1.6031\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.4651 - val_loss: 1.5819\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.4371 - val_loss: 1.5630\n",
      "Epoch 24/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.4105 - val_loss: 1.5447\n",
      "Epoch 25/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.3855 - val_loss: 1.5332\n",
      "Epoch 26/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.3608 - val_loss: 1.5197\n",
      "Epoch 27/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.3377 - val_loss: 1.5046\n",
      "Epoch 28/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.3159 - val_loss: 1.4953\n",
      "Epoch 29/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.2950 - val_loss: 1.4830\n",
      "Epoch 30/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.2740 - val_loss: 1.4737\n",
      "Epoch 31/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.2552 - val_loss: 1.4655\n",
      "Epoch 32/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.2368 - val_loss: 1.4485\n",
      "Epoch 33/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.2187 - val_loss: 1.4466\n",
      "Epoch 34/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.2018 - val_loss: 1.4399\n",
      "Epoch 35/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.1859 - val_loss: 1.4305\n",
      "Epoch 36/50\n",
      "938/938 [==============================] - 131s 139ms/step - loss: 1.1705 - val_loss: 1.4243\n",
      "Epoch 37/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.1554 - val_loss: 1.4179\n",
      "Epoch 38/50\n",
      "938/938 [==============================] - 131s 139ms/step - loss: 1.1406 - val_loss: 1.4092\n",
      "Epoch 39/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.1262 - val_loss: 1.4079\n",
      "Epoch 40/50\n",
      "938/938 [==============================] - 131s 139ms/step - loss: 1.1123 - val_loss: 1.3970\n",
      "Epoch 41/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.0977 - val_loss: 1.3950\n",
      "Epoch 42/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.0834 - val_loss: 1.3835\n",
      "Epoch 43/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.0687 - val_loss: 1.3717\n",
      "Epoch 44/50\n",
      "938/938 [==============================] - 131s 140ms/step - loss: 1.0539 - val_loss: 1.3700\n",
      "Epoch 45/50\n",
      "938/938 [==============================] - 131s 139ms/step - loss: 1.0401 - val_loss: 1.3633\n",
      "Epoch 46/50\n",
      "938/938 [==============================] - 131s 139ms/step - loss: 1.0287 - val_loss: 1.3667\n",
      "Epoch 47/50\n",
      "938/938 [==============================] - 131s 139ms/step - loss: 1.0173 - val_loss: 1.3682\n",
      "Epoch 48/50\n",
      "938/938 [==============================] - 131s 139ms/step - loss: 1.0067 - val_loss: 1.3588\n",
      "Epoch 49/50\n",
      "938/938 [==============================] - 131s 139ms/step - loss: 0.9977 - val_loss: 1.3579\n",
      "Epoch 50/50\n",
      "938/938 [==============================] - 131s 139ms/step - loss: 0.9879 - val_loss: 1.3564\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[encoder_input_train, decoder_input_train],\n",
    "                    y=decoder_target_train,\n",
    "                    validation_data = ([encoder_input_test, decoder_input_test],decoder_target_test),\n",
    "                    batch_size=32,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49f9cc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7eb51c",
   "metadata": {},
   "source": [
    "### Step 5. 모델 구현하기\n",
    "\n",
    "글자 단위 번역기에서 구현한 모델을 참고로 단어 단위 번역기의 모델을 완성시켜보세요! 이때는 label이 integer 값이므로 categorical entropy loss가 아닌 sparse categorical entropy loss를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28829f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 1024)        5934080   \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 1024)        0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                [(None, 1024), (None, 102 8392704   \n",
      "=================================================================\n",
      "Total params: 14,326,784\n",
      "Trainable params: 14,326,784\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e235dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(embedding_size,))\n",
    "decoder_state_input_c = Input(shape=(embedding_size,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5fdbc5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00f6e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 1024)   8496128     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 1024), 8392704     embedding_2[0][0]                \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 8297)   68848506    lstm_3[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 85,737,338\n",
      "Trainable params: 85,737,338\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs2]+decoder_states2)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919d520a",
   "metadata": {},
   "source": [
    "### Step 6. 모델 평가하기\n",
    "\n",
    "단어 단위 번역기를 이용하여 훈련 데이터의 샘플과 테스트 데이터의 샘플로 번역 문장을 만들어보고 정답 문장과 번역 문장을 비교해보세요. 이전 스텝들에서 우리가 공부했던 모델의 경우 글자 단위에서 구현된 번역기이며 현재 프로젝트를 진행할 때 사용하는 모델은 단어 단위에서 구현되는 번역기입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "18509191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 7.6732327e-08, -1.5844066e-07,  1.3096119e-02, ...,\n",
       "         -3.1269334e-05, -9.9831653e-01, -1.7193841e-03]], dtype=float32),\n",
       " array([[ 3.5751251e-05, -6.4210324e+00,  1.0067167e+00, ...,\n",
       "         -9.9958062e-01, -5.1681585e+00, -8.6014410e-03]], dtype=float32)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.predict(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "656304a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <start>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = fra2idx['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이전 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<end>' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80cb9734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + idx2eng[i]+' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "177ef1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=fra2idx['<start>']) and i!=fra2idx['<end>']):\n",
    "            temp = temp + idx2fra[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ee08eda",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/functional.py:414 call\n        return self._run_internal_graph(\n    /opt/conda/lib/python3.9/site-packages/keras/engine/functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense_2 is incompatible with the layer: expected axis -1 of input shape to have value 8297 but received input with shape (None, 1, 1024)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/3050315475.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m87\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1566\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2443\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'입력 문장:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2src\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31/1820034167.py\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# 예측 결과를 문자로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m-> 3038\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3457\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3459\u001b[0;31m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[1;32m   3460\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3379\u001b[0m           expand_composites=True)\n\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3381\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   3382\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/functional.py:414 call\n        return self._run_internal_graph(\n    /opt/conda/lib/python3.9/site-packages/keras/engine/functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense_2 is incompatible with the layer: expected axis -1 of input shape to have value 8297 but received input with shape (None, 1, 1024)\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [2,3,87,1566,2443]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', seq2src(encoder_input_test[seq_index]))\n",
    "    print('정답 문장:', seq2tar(decoder_input_test[seq_index]))\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0a17eaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
